import streamlit as st
import asyncio
import json
import os
from typing import List, Dict, Any, Optional, Union
import logging
import traceback
import sys
from contextlib import asynccontextmanager
import threading
import time

# Importa√ß√µes corrigidas para usar o padr√£o genai.Client
from mcp.client.sse import sse_client
from mcp import ClientSession, types as mcp_types
from google import genai # Usar este, conforme seu exemplo
from google.genai import types # Usar este, conforme seu exemplo
from dotenv import load_dotenv

# Configura√ß√£o especial do asyncio para Streamlit
import nest_asyncio
nest_asyncio.apply()

# For√ßa o uso de SelectorEventLoop no Windows para evitar problemas de concorr√™ncia
if sys.platform.startswith('win'):
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

load_dotenv()

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Configura√ß√µes ---
MCP_SERVER_URL = os.getenv("MCP_SERVER_URL")
if not MCP_SERVER_URL:
    st.error("Erro de configura√ß√£o: A vari√°vel de ambiente MCP_SERVER_URL n√£o est√° definida.")
    st.stop()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("Erro de configura√ß√£o: A vari√°vel de ambiente GEMINI_API_KEY n√£o est√° definida.")
    st.stop()

# --- Streamlit UI Setup (carrega primeiro) ---
st.set_page_config(page_title="Chatbot MCP", page_icon="üí°", layout="wide")
st.title("üîå EIA Energy Data Chatbot")
st.caption("üí° Powered by MCP & Gemini | Pergunte about dados de energia da EIA")

# --- Estado da Aplica√ß√£o ---
if "initialization_complete" not in st.session_state:
    st.session_state.initialization_complete = False
if "connection_status" not in st.session_state:
    st.session_state.connection_status = {"status": "unknown", "message": "N√£o testado"}
if "messages" not in st.session_state:
    st.session_state.messages = []
if "server_wake_attempted" not in st.session_state:
    st.session_state.server_wake_attempted = False

# --- Utilit√°rios para Tratamento de Exce√ß√µes ---
def extract_nested_exception_details(exception: Exception) -> Dict[str, Any]:
    """Extrai detalhes de exce√ß√µes aninhadas, incluindo ExceptionGroup/TaskGroup."""
    details = {
        "type": type(exception).__name__,
        "message": str(exception),
        "nested_exceptions": []
    }
    
    # Verifica se √© um ExceptionGroup (Python 3.11+) ou tem atributo exceptions
    if hasattr(exception, 'exceptions') and exception.exceptions:
        for i, sub_exception in enumerate(exception.exceptions):
            sub_details = extract_nested_exception_details(sub_exception)
            sub_details["index"] = i
            details["nested_exceptions"].append(sub_details)
    
    # Verifica se tem __cause__ ou __context__
    if exception.__cause__:
        details["cause"] = extract_nested_exception_details(exception.__cause__)
    if exception.__context__ and exception.__context__ != exception.__context__:
        details["context"] = extract_nested_exception_details(exception.__context__)
    
    return details

def format_exception_message(exception: Exception) -> str:
    """Formata uma mensagem de erro user-friendly a partir de uma exce√ß√£o."""
    details = extract_nested_exception_details(exception)
    
    def _format_recursive(details_dict: Dict, level: int = 0) -> str:
        indent = "  " * level
        message = f"{indent}‚Ä¢ {details_dict['type']}: {details_dict['message']}\n"
        
        for nested in details_dict.get("nested_exceptions", []):
            message += _format_recursive(nested, level + 1)
        
        if "cause" in details_dict:
            message += f"{indent}Causado por:\n"
            message += _format_recursive(details_dict["cause"], level + 1)
        
        return message
    
    return _format_recursive(details).strip()

async def wait_for_server_ready(server_url: str, max_wait_time: int = 120) -> bool:
    """
    Aguarda at√© que o servidor MCP esteja realmente pronto para aceitar conex√µes.
    """
    import httpx
    
    base_url = server_url.replace('/sse', '')
    start_time = time.time()
    
    logger.info(f"Aguardando servidor MCP ficar pronto: {base_url}")
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        while (time.time() - start_time) < max_wait_time:
            try:
                # Tenta o endpoint SSE diretamente
                response = await client.get(server_url, timeout=10.0)
                if response.status_code == 200:
                    logger.info("Servidor MCP est√° respondendo corretamente")
                    return True
            except Exception as e:
                logger.debug(f"Servidor ainda n√£o est√° pronto: {e}")
            
            await asyncio.sleep(3)  # Aguarda 3 segundos entre tentativas
    
    logger.warning(f"Servidor n√£o ficou pronto em {max_wait_time}s")
    return False

# --- Fun√ß√£o para "Acordar" o Servidor ---
async def wake_up_server(server_url: str) -> bool:
    """
    Tenta acordar um servidor que pode estar em cold start (como Render.com).
    Vers√£o melhorada com mais tempo de espera.
    """
    import httpx
    
    base_url = server_url.replace('/sse', '')
    health_endpoints = [
        f"{base_url}/health",
        f"{base_url}/status", 
        f"{base_url}/",
        server_url  # Tenta o pr√≥prio endpoint SSE
    ]
    
    logger.info(f"Tentando acordar servidor: {base_url}")
    
    async with httpx.AsyncClient(timeout=30.0) as client:  # Timeout maior
        for attempt in range(3):
            for endpoint in health_endpoints:
                try:
                    logger.info(f"Wake-up attempt {attempt + 1}: {endpoint}")
                    response = await client.get(endpoint)
                    if response.status_code < 500:
                        logger.info(f"Servidor respondeu: {endpoint} -> {response.status_code}")
                        # CORRE√á√ÉO: Aguardar mais tempo para estabiliza√ß√£o
                        await asyncio.sleep(8)  # Aumentado de 2s para 8s
                        
                        # CORRE√á√ÉO: Verificar se servidor est√° realmente pronto
                        if await wait_for_server_ready(server_url, max_wait_time=60):
                            return True
                        else:
                            logger.warning("Servidor respondeu mas n√£o est√° pronto para MCP")
                            continue
                            
                except Exception as e:
                    logger.debug(f"Wake-up falhou para {endpoint}: {e}")
                    continue
            
            if attempt < 2:
                wait_time = (attempt + 1) * 10  # CORRE√á√ÉO: 10s, 20s (mais tempo)
                logger.info(f"Esperando {wait_time}s antes da pr√≥xima tentativa...")
                await asyncio.sleep(wait_time)
    
    return False

# --- Context Manager para Sess√µes MCP com Wake-up ---
@asynccontextmanager
async def mcp_session(server_url: str, timeout: float = 45.0, wake_up: bool = True):
    """Context manager para gerenciar sess√µes MCP com cleanup adequado e wake-up opcional."""
    session = None
    streams = None
    try:
        # Tentar acordar o servidor se solicitado
        if wake_up and not st.session_state.server_wake_attempted:
            logger.info("Tentando acordar servidor MCP...")
            wake_success = await wake_up_server(server_url)
            st.session_state.server_wake_attempted = True
            if wake_success:
                logger.info("Servidor acordado com sucesso")
                # CORRE√á√ÉO: Aguardar mais tempo ap√≥s acordar o servidor
                await asyncio.sleep(5)
            else:
                logger.warning("N√£o foi poss√≠vel confirmar se o servidor acordou")
        
        logger.info(f"Estabelecendo conex√£o MCP com {server_url}")
        
        # CORRE√á√ÉO: Timeout mais longo para conex√£o inicial
        streams = sse_client(server_url)
        in_stream, out_stream = await asyncio.wait_for(
            streams.__aenter__(), 
            timeout=timeout
        )
        
        session = ClientSession(in_stream, out_stream)
        
        # CORRE√á√ÉO: Timeout muito mais longo para inicializa√ß√£o e retry logic
        init_timeout = max(30.0, timeout / 2)  # Pelo menos 30s para inicializa√ß√£o
        max_init_retries = 2
        
        for attempt in range(max_init_retries + 1):
            try:
                logger.info(f"Tentativa {attempt + 1} de inicializa√ß√£o da sess√£o MCP")
                await asyncio.wait_for(session.initialize(), timeout=init_timeout)
                logger.info("Sess√£o MCP inicializada com sucesso")
                break
            except asyncio.TimeoutError:
                if attempt < max_init_retries:
                    logger.warning(f"Timeout na inicializa√ß√£o (tentativa {attempt + 1}). Tentando novamente...")
                    await asyncio.sleep(2)
                    continue
                else:
                    raise asyncio.TimeoutError(f"Timeout na inicializa√ß√£o da sess√£o MCP ap√≥s {attempt + 1} tentativas")
        
        yield session
        
    except asyncio.TimeoutError as e:
        logger.error(f"Timeout ao conectar com MCP: {e}")
        if "inicializa√ß√£o" in str(e):
            raise Exception(f"Timeout na inicializa√ß√£o da sess√£o MCP. O servidor est√° respondendo mas n√£o consegue completar o handshake. Tente novamente.")
        else:
            raise Exception(f"Timeout na conex√£o MCP ap√≥s {timeout}s. O servidor pode estar em cold start. Tente novamente em alguns momentos.")
    except Exception as e:
        logger.error(f"Erro na sess√£o MCP: {e}")
        raise
    finally:
        logger.info("Limpando recursos da sess√£o MCP")
        try:
            if session:
                # CORRE√á√ÉO: Cleanup mais robusto
                if hasattr(session, 'close'):
                    await asyncio.wait_for(session.close(), timeout=5.0)
                elif hasattr(session, '_transport') and session._transport:
                    if hasattr(session._transport, 'close'):
                        await asyncio.wait_for(session._transport.close(), timeout=5.0)
        except Exception as cleanup_error:
            logger.warning(f"Erro durante cleanup da sess√£o: {cleanup_error}")
        
        try:
            if streams:
                await asyncio.wait_for(streams.__aexit__(None, None, None), timeout=5.0)
        except Exception as cleanup_error:
            logger.warning(f"Erro durante cleanup dos streams: {cleanup_error}")

# --- Fun√ß√£o para Executar Tool Call com Timeout ---
async def execute_tool_call_safe(session: ClientSession, tool_name: str, tool_args: dict, timeout: float = 45.0) -> Union[Dict, List]:
    """
    Executa uma chamada de ferramenta no servidor MCP com timeout e tratamento robusto de erros.
    """
    try:
        logger.info(f"Executando ferramenta: {tool_name} com argumentos: {tool_args}")
        
        # Executa a chamada da ferramenta com timeout
        result = await asyncio.wait_for(
            session.call_tool(tool_name, arguments=tool_args),
            timeout=timeout
        )

        if hasattr(result, 'content') and result.content is not None:
            tool_output_content = []
            for item in result.content:
                if hasattr(item, 'model_dump'): # Pydantic v2
                    tool_output_content.append(item.model_dump())
                elif hasattr(item, 'dict'): # Pydantic v1
                    tool_output_content.append(item.dict())
                elif hasattr(item, '__dict__'): # Generic object
                    tool_output_content.append(vars(item))
                else:
                    tool_output_content.append(str(item))

            if len(tool_output_content) == 1 and isinstance(tool_output_content[0], dict):
                return tool_output_content[0]
            return tool_output_content if tool_output_content else {"result": "Nenhum conte√∫do retornado", "tool_name": tool_name}
        else:
            return {"result": "Nenhum conte√∫do retornado ou formato inesperado", "tool_name": tool_name}

    except asyncio.TimeoutError:
        error_msg = f"Timeout ao executar ferramenta {tool_name} (>{timeout}s)"
        logger.error(error_msg)
        return {"error": error_msg, "tool_name": tool_name, "type": "TimeoutError"}
    
    except Exception as e:
        error_msg = f"Erro ao executar ferramenta {tool_name}: {format_exception_message(e)}"
        logger.error(error_msg)
        logger.error(f"Traceback completo: {traceback.format_exc()}")

        return {
            "error": str(e),
            "tool_name": tool_name,
            "type": type(e).__name__,
            "formatted_error": format_exception_message(e)
        }

# --- Teste de Conex√£o Ass√≠ncrono com Retry Logic ---
async def test_mcp_connection_async(server_url: str, max_retries: int = 2) -> tuple[bool, str]:
    """Testa a conex√£o com o servidor MCP de forma ass√≠ncrona com retry logic."""
    for attempt in range(max_retries + 1):
        try:
            # CORRE√á√ÉO: Timeouts mais longos e progressivos
            timeout = 45.0 if attempt == 0 else 90.0  # Aumentado significativamente
            wake_up = attempt > 0
            
            if attempt > 0:
                logger.info(f"Tentativa {attempt + 1} de conex√£o MCP (timeout: {timeout}s)")
                # CORRE√á√ÉO: Aguardar mais tempo entre tentativas
                await asyncio.sleep(5)
            
            async with mcp_session(server_url, timeout=timeout, wake_up=wake_up) as session:
                # CORRE√á√ÉO: Timeout mais longo para list_tools
                tools = await asyncio.wait_for(session.list_tools(), timeout=30.0)
                success_msg = f"Conex√£o bem-sucedida. {len(tools.tools)} ferramentas dispon√≠veis."
                if attempt > 0:
                    success_msg += f" (Sucesso na tentativa {attempt + 1})"
                return True, success_msg
                
        except Exception as e:
            error_formatted = format_exception_message(e)
            logger.error(f"Tentativa {attempt + 1} falhou: {error_formatted}")
            
            # Se n√£o √© a √∫ltima tentativa, continua
            if attempt < max_retries:
                wait_time = (attempt + 1) * 5  # CORRE√á√ÉO: Aguardar mais tempo - 5s, 10s
                logger.info(f"Aguardando {wait_time}s antes da pr√≥xima tentativa...")
                await asyncio.sleep(wait_time)
                continue
            
            # √öltima tentativa falhou - formatar erro para o usu√°rio
            error_str = str(e).lower()
            if any(keyword in error_str for keyword in ['timeout', 'inicializa√ß√£o', 'handshake']):
                return False, f"‚ùå Timeout na conex√£o/inicializa√ß√£o. O servidor MCP est√° respondendo mas n√£o consegue completar a inicializa√ß√£o. Isso √© comum em servi√ßos gratuitos. Aguarde 1-2 minutos e tente novamente."
            elif any(keyword in error_str for keyword in ['cold start']):
                return False, f"‚ùå Servidor em cold start. Aguarde 2-3 minutos e tente novamente."
            elif any(keyword in error_str for keyword in ['connection', 'refused', 'unreachable', '404']):
                return False, f"‚ùå Servidor MCP inacess√≠vel: {server_url}"
            else:
                return False, f"‚ùå Erro de conex√£o: {str(e)}"

def test_mcp_connection_sync(server_url: str) -> tuple[bool, str]:
    """Wrapper s√≠ncrono para teste de conex√£o."""
    try:
        return asyncio.run(test_mcp_connection_async(server_url))
    except Exception as e:
        error_formatted = format_exception_message(e)
        logger.error(f"Erro cr√≠tico no teste de conex√£o: {error_formatted}")
        return False, f"‚ùå Erro cr√≠tico: {str(e)}"

# --- Fun√ß√£o Principal com Melhor Isolamento de Asyncio ---
async def process_query_with_tools_safe(query: str, gemini_client: genai.Client, sse_url: str):
    """
    Processa uma query usando conex√£o MCP isolada e o modelo Gemini.
    """
    try:
        # Timeout mais longo para opera√ß√µes de query
        async with mcp_session(sse_url, timeout=120.0, wake_up=False) as session:
            # Obter ferramentas dispon√≠veis
            tools_result = await asyncio.wait_for(session.list_tools(), timeout=30.0)
            available_tool_declarations = []
            for tool in tools_result.tools:
                available_tool_declarations.append({
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.inputSchema
                })

            logger.info(f"Ferramentas dispon√≠veis: {[t['name'] for t in available_tool_declarations]}")

            # Prompt de sistema otimizado
            system_instruction = """
            Voc√™ √© um assistente especializado em dados de energia da U.S. Energy Information Administration (EIA), acessando dados atrav√©s de uma API v2.
            Seu objetivo √© responder √†s perguntas dos usu√°rios usando as ferramentas fornecidas: `list_eia_v2_routes`, `get_eia_v2_route_data`, e `get_eia_v2_series_id_data`.

            **REGRAS CR√çTICAS PARA USO DAS FERRAMENTAS:**

            1.  **SEMPRE verifique se h√° erros nos resultados das ferramentas antes de prosseguir.**
            2.  **Se uma ferramenta retornar erro, explique o problema e tente uma abordagem alternativa.**
            3.  **FLUXO DE DESCOBERTA OBRIGAT√ìRIO (para perguntas abertas sobre dados):**
                *   **N√ÉO assuma rotas ou IDs.** Para perguntas como "Qual a produ√ß√£o de X em Y?" ou "Dados sobre Z", voc√™ DEVE seguir este fluxo:
                *   **Passo 1:** Comece com `list_eia_v2_routes()` (sem argumentos) para ver as categorias de n√≠vel superior.
                *   **Passo 2:** Analise a sa√≠da. Se uma categoria parecer relevante (ex: "petroleum"), chame `list_eia_v2_routes(segment_path="nome_da_categoria")` para ver sub-rotas e metadados.
                *   **Passo 3:** Continue chamando `list_eia_v2_routes` com `segment_path` cada vez mais espec√≠fico at√© encontrar os dados necess√°rios.

            4.  **TRATAMENTO DE ERROS:**
                *   Se encontrar um erro de "TaskGroup" ou similar, informe que houve um problema t√©cnico e tente uma abordagem diferente.
                *   Se uma ferramenta falhar, n√£o desista - tente uma rota alternativa ou explique as limita√ß√µes.

            5.  **ANO CORRENTE:**
                *   Para "este ano" ou "ano corrente", use 2024 como refer√™ncia.

            **IMPORTANTE:** Sempre verifique se o resultado de uma ferramenta cont√©m um erro antes de interpret√°-lo como dados v√°lidos.
            """

            # Inicializa a sess√£o de chat
            chat = gemini_client.chats.create(
                model="gemini-1.5-flash-001",
                tools=available_tool_declarations,
                config=types.GenerateContentConfig(temperature=0.1),
                history=[
                    types.Content(
                        role="user",
                        parts=[types.Part(text=system_instruction)]
                    ),
                    types.Content(
                        role="model",
                        parts=[types.Part(text="Ol√°! Como posso ajudar com os dados de energia da EIA hoje?")]
                    )
                ]
            )
            
            # Processar itera√ß√µes
            max_iterations = 6  # Reduzido para evitar loops longos
            iteration_count = 0
            final_response_content = "Processamento conclu√≠do sem resposta final."

            current_user_message_parts = [types.Part(text=query)]

            while iteration_count < max_iterations:
                iteration_count += 1
                logger.info(f"Itera√ß√£o {iteration_count} do loop de processamento")
                
                try:
                    # Envia mensagem com timeout
                    gemini_response = await asyncio.wait_for(
                        chat.send_message_async(current_user_message_parts),
                        timeout=60.0
                    )
                    
                    response_text_parts = []
                    tool_calls_for_processing = []

                    for part in gemini_response.parts:
                        if hasattr(part, 'text'):
                            response_text_parts.append(part.text)
                        elif hasattr(part, 'function_call'):
                            tool_calls_for_processing.append(part.function_call)
                    
                    current_llm_text_response = "".join(response_text_parts)

                    if current_llm_text_response:
                        st.markdown(current_llm_text_response)
                        final_response_content = current_llm_text_response

                    if tool_calls_for_processing:
                        tool_outputs_parts = []
                        
                        # Processa as chamadas de ferramenta sequencialmente
                        for tool_call in tool_calls_for_processing:
                            tool_name = tool_call.name
                            try:
                                tool_args = dict(tool_call.args)
                            except Exception as e:
                                st.error(f"Erro ao converter argumentos da ferramenta {tool_name}: {tool_call.args}. Erro: {e}")
                                tool_output_data = {
                                    "error": f"Erro ao converter argumentos: {e}", 
                                    "arguments_received": str(tool_call.args)
                                }
                            else:
                                tool_output_data = await execute_tool_call_safe(session, tool_name, tool_args)
                            
                            # Mostra resultado da ferramenta
                            st.info(f"üîß Executando: {tool_name}")
                            if isinstance(tool_output_data, dict) and "error" in tool_output_data:
                                st.error(f"‚ùå Erro na ferramenta: {tool_output_data.get('error', 'Erro desconhecido')}")
                            else:
                                st.success(f"‚úÖ Resultado obtido")
                                with st.expander(f"Ver dados de {tool_name}", expanded=False):
                                    st.json(tool_output_data)

                            tool_outputs_parts.append(
                                types.Part(function_response={
                                    'name': tool_name,
                                    'response': tool_output_data
                                })
                            )
                        
                        current_user_message_parts = tool_outputs_parts
                        
                    else:
                        # Sem mais chamadas de ferramenta - terminar
                        break
                        
                except asyncio.TimeoutError:
                    error_msg = "‚è∞ Timeout ao comunicar com o modelo Gemini. Tente uma pergunta mais simples."
                    st.error(error_msg)
                    final_response_content = error_msg
                    break
                    
                except types.BlockedPromptException as e:
                    error_msg = f"üö´ A resposta foi bloqueada devido a pol√≠ticas de seguran√ßa: {e.safety_ratings}"
                    st.error(error_msg)
                    logger.error(f"Gemini BlockedPromptException: {e}")
                    final_response_content = error_msg
                    break

                except Exception as e:
                    error_formatted = format_exception_message(e)
                    logger.error(f"Erro na itera√ß√£o {iteration_count}: {error_formatted}")
                    logger.error(f"Traceback: {traceback.format_exc()}")
                    
                    # Verifica se √© um erro conhecido de concorr√™ncia
                    error_str = str(e).lower()
                    if any(keyword in error_str for keyword in ['taskgroup', 'exceptiongroup', 'unhandled errors']):
                        error_msg = "‚ö†Ô∏è Erro t√©cnico de concorr√™ncia detectado. Tente reformular sua pergunta ou tente novamente."
                        st.error(error_msg)
                        with st.expander("Detalhes t√©cnicos", expanded=False):
                            st.text(error_formatted)
                        final_response_content = error_msg
                        break
                    else:
                        # Re-raise outros erros
                        raise

            if iteration_count >= max_iterations:
                warning_msg = "‚ö†Ô∏è Limite m√°ximo de itera√ß√µes atingido. A resposta pode estar incompleta."
                st.warning(warning_msg)
                final_response_content += f"\n\n{warning_msg}"
            
            return final_response_content
                
    except Exception as e:
        error_formatted = format_exception_message(e)
        logger.error(f"Erro cr√≠tico em process_query_with_tools_safe: {error_formatted}")
        logger.error(f"Traceback completo: {traceback.format_exc()}")
        
        # Categoriza o erro para o usu√°rio
        error_str = str(e).lower()
        if any(keyword in error_str for keyword in ['taskgroup', 'exceptiongroup', 'unhandled errors']):
            user_msg = "‚ùå Erro de concorr√™ncia detectado. Isso pode acontecer em ambientes com m√∫ltiplas opera√ß√µes ass√≠ncronas. Tente novamente."
        elif any(keyword in error_str for keyword in ['timeout']):
            user_msg = f"‚ùå Timeout na opera√ß√£o. O servidor pode estar lento ou em cold start."
        elif any(keyword in error_str for keyword in ['connection', 'refused', 'unreachable']):
            user_msg = f"‚ùå Erro de conex√£o com o servidor MCP ({MCP_SERVER_URL}). Verifique se o servidor est√° rodando."
        else:
            user_msg = f"‚ùå Erro inesperado: {type(e).__name__}: {str(e)}"
        
        raise Exception(user_msg) from e

# --- Cliente Principal ---
class MCP_ChatBotClient:
    def __init__(self, mcp_server_url: str, gemini_client: genai.Client):
        self.mcp_server_url = mcp_server_url
        self.gemini_client = gemini_client

    async def process_query(self, query: str):
        """Processa uma query usando conex√£o MCP isolada."""
        return await process_query_with_tools_safe(query, self.gemini_client, self.mcp_server_url)

# --- Inicializa√ß√£o do Cliente Gemini (primeira coisa a ser feita) ---
if "gemini_client_instance" not in st.session_state:
    try:
        st.session_state.gemini_client_instance = genai.Client(api_key=GEMINI_API_KEY)
        logger.info("Cliente Gemini inicializado com sucesso")
    except Exception as e:
        st.error(f"‚ùå Erro ao inicializar cliente Gemini: {e}")
        st.stop()

if "mcp_chatbot_client" not in st.session_state:
    st.session_state.mcp_chatbot_client = MCP_ChatBotClient(
        MCP_SERVER_URL,
        st.session_state.gemini_client_instance
    )

# --- Layout Principal e Sidebar ---
col1, col2 = st.columns([3, 1])

# --- Sidebar (sempre vis√≠vel) ---
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    st.markdown(f"**üåê Servidor MCP:** `{MCP_SERVER_URL}`")
    
    # Status da conex√£o
    if st.session_state.connection_status["status"] == "unknown":
        st.markdown("**üìä Status:** üü° N√£o testado")
    elif st.session_state.connection_status["status"] == "ok":
        st.markdown("**üìä Status:** üü¢ Conectado")
    else:
        st.markdown("**üìä Status:** üî¥ Desconectado")
    
    st.markdown("---")
    
    # Bot√£o para testar conex√£o
    if st.button("üîç Testar Conex√£o MCP"):
        with st.spinner("Testando conex√£o... (pode demorar se o servidor estiver em cold start)"):
            connection_ok, connection_msg = test_mcp_connection_sync(MCP_SERVER_URL)
            st.session_state.connection_status = {
                "status": "ok" if connection_ok else "error",
                "message": connection_msg
            }
        st.rerun()
    
    # Mostra resultado do √∫ltimo teste
    if st.session_state.connection_status["status"] != "unknown":
        if st.session_state.connection_status["status"] == "ok":
            st.success(st.session_state.connection_status["message"])
        else:
            st.error("Erro na conex√£o:")
            st.text(st.session_state.connection_status["message"])
    
    # Bot√£o para resetar estado do servidor
    if st.button("üîÑ Reset Server State"):
        st.session_state.server_wake_attempted = False
        st.session_state.connection_status = {"status": "unknown", "message": "Estado resetado"}
        st.success("Estado do servidor resetado. Teste a conex√£o novamente.")
        st.rerun()
    
    if st.button("üóëÔ∏è Limpar Chat"):
        st.session_state.messages = []
        st.rerun()
    
    if st.button("üîß Diagn√≥stico Completo"):
        st.markdown("### üîç Executando diagn√≥stico...")
        
        # Verificar configura√ß√µes
        if not MCP_SERVER_URL:
            st.error("‚ùå URL do servidor MCP n√£o configurada")
        else:
            st.success(f"‚úÖ URL configurada")
        
        if not GEMINI_API_KEY:
            st.error("‚ùå Chave API Gemini n√£o configurada")
        else:
            st.success("‚úÖ Chave API Gemini configurada")
        
        # Testar imports
        try:
            from mcp.client.sse import sse_client
            st.success("‚úÖ Imports MCP OK")
        except ImportError as e:
            st.error(f"‚ùå Erro de import MCP: {e}")
        
        try:
            import google.genai as genai_test
            test_client = genai_test.Client(api_key="DUMMY_KEY")
            st.success("‚úÖ Imports Google Generative AI OK")
        except Exception as e:
            st.error(f"‚ùå Erro Google Generative AI: {e}")

# --- Conte√∫do Principal ---
with col1:
    # Mostra mensagens do hist√≥rico
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- Interface de Chat ---
    # S√≥ permite chat se a conex√£o foi testada e est√° OK
    if st.session_state.connection_status["status"] == "ok":
        if prompt := st.chat_input("Digite sua pergunta sobre dados de energia..."):
            # Adicionar mensagem do usu√°rio
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("user"):
                st.markdown(prompt)

            # Processar resposta do assistente
            with st.chat_message("assistant"):
                with st.spinner("ü§ñ Analisando sua pergunta e consultando dados..."):
                    try:
                        # Cria uma nova task para isolar o processamento
                        response = asyncio.run(
                            st.session_state.mcp_chatbot_client.process_query(prompt)
                        )
                        
                        if response:
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": response
                            })
                            
                    except Exception as e:
                        error_formatted = format_exception_message(e)
                        logger.error(f"Erro ao processar consulta: {error_formatted}")
                        
                        # Erro mais user-friendly
                        error_str = str(e).lower()
                        if any(keyword in error_str for keyword in ['taskgroup', 'exceptiongroup', 'concorr√™ncia']):
                            error_msg = """
                            ‚ö†Ô∏è **Erro de concorr√™ncia detectado**
                            
                            Isso pode acontecer devido a opera√ß√µes ass√≠ncronas conflitantes. 
                            
                            **Sugest√µes:**
                            - Tente reformular sua pergunta
                            - Fa√ßa perguntas mais espec√≠ficas
                            - Aguarde alguns segundos antes de tentar novamente
                            """
                        else:
                            error_msg = f"‚ùå **Erro ao processar consulta:**\n\n{str(e)}"
                        
                        st.error(error_msg)
                        
                        with st.expander("üîç Detalhes t√©cnicos", expanded=False):
                            st.text(error_formatted)
                        
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": error_msg
                        })
    
    elif st.session_state.connection_status["status"] == "error":
        st.warning("‚ö†Ô∏è **Chatbot indispon√≠vel** - Problemas de conex√£o com o servidor MCP")
        st.info("üí° Use o bot√£o 'Testar Conex√£o MCP' na barra lateral para verificar o status.")
    
    else:
        st.info("üîç **Teste a conex√£o primeiro**")
        st.info("üí° Use o bot√£o 'Testar Conex√£o MCP' na barra lateral para come√ßar.")

# --- Footer ---
st.markdown("---")
st.markdown("üîó **EIA Energy Data Chatbot** | Dados em tempo real da U.S. Energy Information Administration")